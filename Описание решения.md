1. хотели реализовать тг бота для выдачи наших релевантных новостей каждые 10-15 минут,
в дальнейшем, можно было бы прокачать это все на какие-то "умные часы" для выдачи информации. 
Например, не выдавать новости такими пачками по ночам и в неудобное время для людей или сделать выбор по конкретным часам или частоте публикации
новости конкретному юзеру. Для этого есть все, достаточно расширить нашу бд и устанавливать числовые флаги для регуляции отправки сообщении
и добавить несколько лишних проверок.
2. Все наши запросы обновляются раз в 10 минут, то есть парсер собирает всегда все самые свежие новости, далее идет модельная часть.
3. Хотели реализовать весь алгоритм через добавления всего массива в базу данных на новый лист и взаимодействовать там с ней 
(обновление запросов, обновление обучающего дата сета, флаги для неповторяющихся новостей).
4. Все ошибки поступают и обрабатываются на стороне сервера, при некритических ошибках программа продолжает работать далее. 
Наше API имеет свое приложение (черная консоль), понятный администраторам. 
Для пользователей ошибки не выходят и не будут его пугать своими массами и присутствием в самой реализации бота.
5. Наша реализация данной задачи, ее конечный продукт работает как подписка на новостные каналы\сайты и тд. 
Наше приемущество заключается в том, что А - новости отслеживаются из многих (нескольких) крупных каналов связи и 
из-за нашего алгоритма машинного обучения выбираются самые релевантные новости из всех недавних (вставить насколько недавних)


Работа модели:

1) create_mini_batch() в файле main.py - сохраняет в папке и возвращает сводку по всем новым новостям, добавляет 4 столбца:
вероятности принадлежности к какому-либо классу
предсказания, 1 - если вероятность больше 1
Предсказания здесь. нужны для работы модели для трендов
2) get_trend() в файле save_trend_txt.py 
возвращает список трендов! для работы файлов уже должен быть сформирован файл df_main.pkl
этот файл своеобразная база данных, на основе которой все работает
по-хорошему она должна обновляться регулярно, но прописывать это не стали, не хватило времени
Возникают проблемы с classifier и vectorizer, при текущей настройке все работает
Если полностью никаких файлов нет, то можно запустить
1) create_full_dataset()
2) generate_vect_clas()
После этого будет все готово
TF-IDF вообще не скачивается, а просто каждый раз заново считаются эти значения на выборке df_main, потому что подсчет проводится очень быстро
